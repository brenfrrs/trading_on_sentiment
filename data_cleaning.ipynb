{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import pytz\n",
    "from nltk.probability import FreqDist\n",
    "from custom_scripts import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading on Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will address the data cleaning steps needed in order to have a dataset suitable for modeling and analysis. We will import all of the yearly articles, convert the datetimes to Eastern Standard Time, tag the sentiment of each article, and combine each article with its historical stock price information for the day it was published. Finally we will tokenize, remove stop words, then aggregate all of the values so that we have one row of information per day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import yearly data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39512, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('yearly_articles/apple2020.csv', index_col=0)\n",
    "df2 = pd.read_csv('yearly_articles/apple2019.csv', index_col=0)\n",
    "df3 = pd.read_csv('yearly_articles/apple2018.csv', index_col=0)\n",
    "df4 = pd.read_csv('yearly_articles/apple2017.csv', index_col=0)\n",
    "df5 = pd.read_csv('yearly_articles/apple2016.csv', index_col=0)\n",
    "df6 = pd.read_csv('yearly_articles/apple2015.csv', index_col=0)\n",
    "df = pd.concat([df1,df2, df3, df4, df5, df6])\n",
    "df.dropna(subset=['fulltext'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean newlines and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 217 ms, total: 11 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['cleaned_text'] = df['fulltext'].apply(clean_text)\n",
    "df['cleaned_authors'] = df['author'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing the UTC time to EST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to Datetime\n",
    "df[\"date\"]= pd.to_datetime(df[\"date\"])\n",
    "df = df.set_index('date')\n",
    "df.index = df.index.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 283 ms, sys: 5.28 ms, total: 288 ms\n",
      "Wall time: 290 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#convert DateTime index to eastern time. \n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "df.index = df.index.tz_convert(eastern).tz_localize(None)\n",
    "#put into year/month/day format\n",
    "df.index = df.index.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using [tldextract](https://pypi.org/project/tldextract/) to extract company names from url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 39512 different articles from 448 news outlets \n",
      "\n",
      "CPU times: user 463 ms, sys: 11 ms, total: 474 ms\n",
      "Wall time: 487 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['news_outlet'] = df['source'].apply(get_outlet)\n",
    "print('The dataset contains {} different articles from {} news outlets \\n'.format(df.shape[0],df.news_outlet.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting historical Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_we_need = [2015, 2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "full_date_list = []\n",
    "\n",
    "for year in years_we_need:\n",
    "    res = get_month_day_range(year)\n",
    "    full_date_list += res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_past_prices` custom function uses a list of dates and a ticker symbol to call the twelvedata.com API for all of the dates in the provided list. In our case we want historical prices over the past 5 years, because we have 5 years worth of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 2015-01-01 to 2015-01-31\n",
      "2) 2015-02-01 to 2015-02-28\n",
      "3) 2015-03-01 to 2015-03-31\n",
      "4) 2015-04-01 to 2015-04-30\n",
      "5) 2015-05-01 to 2015-05-31\n",
      "6) 2015-06-01 to 2015-06-30\n",
      "7) 2015-07-01 to 2015-07-31\n",
      "8) 2015-08-01 to 2015-08-31\n",
      "9) 2015-09-01 to 2015-09-30\n",
      "10) 2015-10-01 to 2015-10-31\n",
      "11) 2015-11-01 to 2015-11-30\n",
      "12) 2015-12-01 to 2015-12-31\n",
      "13) 2016-01-01 to 2016-01-31\n",
      "14) 2016-02-01 to 2016-02-29\n",
      "15) 2016-03-01 to 2016-03-31\n",
      "16) 2016-04-01 to 2016-04-30\n",
      "17) 2016-05-01 to 2016-05-31\n",
      "18) 2016-06-01 to 2016-06-30\n",
      "19) 2016-07-01 to 2016-07-31\n",
      "20) 2016-08-01 to 2016-08-31\n",
      "21) 2016-09-01 to 2016-09-30\n",
      "22) 2016-10-01 to 2016-10-31\n",
      "23) 2016-11-01 to 2016-11-30\n",
      "24) 2016-12-01 to 2016-12-31\n",
      "25) 2017-01-01 to 2017-01-31\n",
      "26) 2017-02-01 to 2017-02-28\n",
      "27) 2017-03-01 to 2017-03-31\n",
      "28) 2017-04-01 to 2017-04-30\n",
      "29) 2017-05-01 to 2017-05-31\n",
      "30) 2017-06-01 to 2017-06-30\n",
      "31) 2017-07-01 to 2017-07-31\n",
      "32) 2017-08-01 to 2017-08-31\n",
      "33) 2017-09-01 to 2017-09-30\n",
      "34) 2017-10-01 to 2017-10-31\n",
      "35) 2017-11-01 to 2017-11-30\n",
      "36) 2017-12-01 to 2017-12-31\n",
      "37) 2018-01-01 to 2018-01-31\n",
      "38) 2018-02-01 to 2018-02-28\n",
      "39) 2018-03-01 to 2018-03-31\n",
      "40) 2018-04-01 to 2018-04-30\n",
      "41) 2018-05-01 to 2018-05-31\n",
      "42) 2018-06-01 to 2018-06-30\n",
      "43) 2018-07-01 to 2018-07-31\n",
      "44) 2018-08-01 to 2018-08-31\n",
      "45) 2018-09-01 to 2018-09-30\n",
      "46) 2018-10-01 to 2018-10-31\n",
      "47) 2018-11-01 to 2018-11-30\n",
      "48) 2018-12-01 to 2018-12-31\n",
      "49) 2019-01-01 to 2019-01-31\n",
      "50) 2019-02-01 to 2019-02-28\n",
      "51) 2019-03-01 to 2019-03-31\n",
      "52) 2019-04-01 to 2019-04-30\n",
      "53) 2019-05-01 to 2019-05-31\n",
      "54) 2019-06-01 to 2019-06-30\n",
      "55) 2019-07-01 to 2019-07-31\n",
      "56) 2019-08-01 to 2019-08-31\n",
      "57) 2019-09-01 to 2019-09-30\n",
      "58) 2019-10-01 to 2019-10-31\n",
      "59) 2019-11-01 to 2019-11-30\n",
      "60) 2019-12-01 to 2019-12-31\n",
      "61) 2020-01-01 to 2020-01-31\n",
      "62) 2020-02-01 to 2020-02-29\n",
      "63) 2020-03-01 to 2020-03-31\n",
      "64) 2020-04-01 to 2020-04-30\n",
      "65) 2020-05-01 to 2020-05-31\n",
      "66) 2020-06-01 to 2020-06-30\n",
      "67) 2020-07-01 to 2020-07-31\n",
      "68) 2020-08-01 to 2020-08-31\n",
      "69) 2020-09-01 to 2020-09-30\n",
      "70) 2020-10-01 to 2020-10-31\n",
      "71) 2020-11-01 to 2020-11-30\n",
      "72) 2020-12-01 to 2020-12-31\n",
      "Final shape: (1456, 5)\n"
     ]
    }
   ],
   "source": [
    "historical_prices = get_past_prices(full_date_list, 'AAPL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loop below iterates through the historical prices and calculates the change in a stock price from one open to another. Adding a 0 if the stock decreased or there was not change, and adding a 1 if the stock increased. This is an initial tagging step, the threshold for targets can be adjusted later using the 'day_change' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_index = historical_prices.index.strftime('%Y-%m-%d').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_prices.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(columns = ['day_change', 'increase', 'date'])\n",
    "for i,stock_price in enumerate(prices_index):\n",
    "    try:\n",
    "        today = historical_prices.loc[prices_index[i]].open\n",
    "        tomorrow = historical_prices.loc[prices_index[i+1]].open\n",
    "        direction = tomorrow - today\n",
    "        if direction < 0:\n",
    "            increase = 0\n",
    "        else:\n",
    "            increase = 1\n",
    "        df_res = df_res.append({'day_change': direction, 'increase':increase, 'date':stock_price}, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_change</th>\n",
       "      <th>increase</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1.55001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>-0.08001</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>-3.86000</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>6.59000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>0.44690</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      day_change increase        date\n",
       "1450     1.55001        1  2020-12-16\n",
       "1451    -0.08001        0  2020-12-17\n",
       "1452    -3.86000        0  2020-12-18\n",
       "1453     6.59000        1  2020-12-21\n",
       "1454     0.44690        1  2020-12-22"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[\"date\"]= pd.to_datetime(df_res[\"date\"])\n",
    "df_res = df_res.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.sort_index(inplace=True)\n",
    "targets = df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the historical prices with the daily change we calculated and the targets. \n",
    "targs=pd.merge(targets,historical_prices, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_change</th>\n",
       "      <th>increase</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-18</th>\n",
       "      <td>0.08001</td>\n",
       "      <td>1</td>\n",
       "      <td>128.8800</td>\n",
       "      <td>129.10001</td>\n",
       "      <td>126.12000</td>\n",
       "      <td>126.65000</td>\n",
       "      <td>108795507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>3.86000</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0200</td>\n",
       "      <td>128.31000</td>\n",
       "      <td>123.44900</td>\n",
       "      <td>128.23000</td>\n",
       "      <td>121251553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-22</th>\n",
       "      <td>-6.59000</td>\n",
       "      <td>0</td>\n",
       "      <td>131.6100</td>\n",
       "      <td>134.41000</td>\n",
       "      <td>129.64999</td>\n",
       "      <td>131.88000</td>\n",
       "      <td>168904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>-0.44690</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0569</td>\n",
       "      <td>132.42000</td>\n",
       "      <td>130.78000</td>\n",
       "      <td>132.04269</td>\n",
       "      <td>48470341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            day_change increase      open       high        low      close  \\\n",
       "2020-12-18     0.08001        1  128.8800  129.10001  126.12000  126.65000   \n",
       "2020-12-21     3.86000        1  125.0200  128.31000  123.44900  128.23000   \n",
       "2020-12-22    -6.59000        0  131.6100  134.41000  129.64999  131.88000   \n",
       "2020-12-23    -0.44690        0  132.0569  132.42000  130.78000  132.04269   \n",
       "\n",
       "               volume  \n",
       "2020-12-18  108795507  \n",
       "2020-12-21  121251553  \n",
       "2020-12-22  168904800  \n",
       "2020-12-23   48470341  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targs.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the targets\n",
    "targs.to_csv('targs_revision.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge targets and main data on the date\n",
    "df=pd.merge(df,targs, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for weekends and holidays when the market is closed. Forward filling of the previous non-NA value is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill', inplace = True)\n",
    "\n",
    "#Drop the few late 2014 values where we have not price data. \n",
    "df.dropna(subset=['increase', 'open', 'high', 'low', 'close'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Sentiment for each Article with VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tag the sentiment of each article, we will use the [VADER](https://github.com/cjhutto/vaderSentiment) sentiment analyzer. The `sentiment_analyzer_scores` custom function inputs a string and output the result of the VADER sentiment prediction. Vader is primarily used for social media text; however, is effective with news articles as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 13s, sys: 18 s, total: 16min 30s\n",
      "Wall time: 20min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#tag the sentiment for each article using VADER. This will take a few minutes.\n",
    "df['sentiment'] = df['fulltext'].apply(sentiment_analyzer_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After predicting sentiment of the article, we can create dummies of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dummies = pd.get_dummies(df['sentiment'], prefix='sent')\n",
    "df = pd.concat([df, sentiment_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>update</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_authors</th>\n",
       "      <th>news_outlet</th>\n",
       "      <th>day_change</th>\n",
       "      <th>increase</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sent_negative</th>\n",
       "      <th>sent_neutral</th>\n",
       "      <th>sent_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>2015-01-03 00:00:00</td>\n",
       "      <td>http://mg.co.za/article/2015-01-03-storage-war...</td>\n",
       "      <td>['Staff Reporter']</td>\n",
       "      <td>Apple on Friday faced a lawsuit accusing it of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storage war: Lawsuit accuses Apple of deceivin...</td>\n",
       "      <td>apple on friday faced a lawsuit accusing it of...</td>\n",
       "      <td>staff reporter</td>\n",
       "      <td>mg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53204600.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>2015-01-03 00:00:00</td>\n",
       "      <td>http://www.independent.ie/business/technology/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Apple is being sued for lack of storage space ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple sued over lack of storage space on devices</td>\n",
       "      <td>apple is being sued for lack of storage space ...</td>\n",
       "      <td></td>\n",
       "      <td>independent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53204600.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         update  \\\n",
       "2015-01-02  2015-01-03 00:00:00   \n",
       "2015-01-02  2015-01-03 00:00:00   \n",
       "\n",
       "                                                       source  \\\n",
       "2015-01-02  http://mg.co.za/article/2015-01-03-storage-war...   \n",
       "2015-01-02  http://www.independent.ie/business/technology/...   \n",
       "\n",
       "                        author  \\\n",
       "2015-01-02  ['Staff Reporter']   \n",
       "2015-01-02                  []   \n",
       "\n",
       "                                                     fulltext  summary  \\\n",
       "2015-01-02  Apple on Friday faced a lawsuit accusing it of...      NaN   \n",
       "2015-01-02  Apple is being sued for lack of storage space ...      NaN   \n",
       "\n",
       "                                                        title  \\\n",
       "2015-01-02  Storage war: Lawsuit accuses Apple of deceivin...   \n",
       "2015-01-02   Apple sued over lack of storage space on devices   \n",
       "\n",
       "                                                 cleaned_text cleaned_authors  \\\n",
       "2015-01-02  apple on friday faced a lawsuit accusing it of...  staff reporter   \n",
       "2015-01-02  apple is being sued for lack of storage space ...                   \n",
       "\n",
       "            news_outlet  day_change  increase  open  high  low  close  \\\n",
       "2015-01-02           mg         0.0       1.0   0.0   0.0  0.0    0.0   \n",
       "2015-01-02  independent         0.0       1.0   0.0   0.0  0.0    0.0   \n",
       "\n",
       "                volume sentiment  sent_negative  sent_neutral  sent_positive  \n",
       "2015-01-02  53204600.0  negative              1             0              0  \n",
       "2015-01-02  53204600.0  negative              1             0              0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['cleaned_text'].apply(toke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize/Stop Word Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three custom functions: `remove_stopwords`, `lemmatize_text`, `unlist` will be used to process the word tokens we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: <function remove_stopwords at 0x7ff1e82f8950>\n",
      "Completed: <function lemmatize_text at 0x7ff1e82f8840>\n",
      "Completed: <function unlist at 0x7ff1e82f8730>\n"
     ]
    }
   ],
   "source": [
    "pre_process = [remove_stopwords, lemmatize_text, unlist]\n",
    "\n",
    "for action in pre_process:\n",
    "    df.tokens = df.tokens.apply(action)\n",
    "    print('Completed: {}'.format(str(action)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure there are no duplicate articles.\n",
    "df.drop_duplicates(subset=['tokens'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate the daily news articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform modeling on the aggregated article text per day. Our data is in a format that has each row as a new article, we want to aggregate all of the articles on a given day into a single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "agged = df.copy()\n",
    "agged.reset_index(inplace=True)\n",
    "agged['date'] = pd.to_datetime(agged['index'])\n",
    "agged.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a column of 1's for when we aggregate all info into one column, we can add the 1's later to get the total articles per day. \n",
    "agged['total_articles'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = agged.groupby('date')['sent_negative', 'sent_positive', 'total_articles'].agg(np.sum)\n",
    "text = agged.groupby('date')['tokens'].agg(''.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "agged = pd.merge(text, sentiment, how='inner', left_index=True, right_index=True)\n",
    "#Merge targets\n",
    "agged = pd.merge(agged, targs, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>sent_negative</th>\n",
       "      <th>sent_positive</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>day_change</th>\n",
       "      <th>increase</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>apple, friday, faced, lawsuit, accusing, promi...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53204600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>heard, much, hyped, apple, watch, would, arriv...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64285500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       tokens  sent_negative  \\\n",
       "2015-01-02  apple, friday, faced, lawsuit, accusing, promi...              5   \n",
       "2015-01-05  heard, much, hyped, apple, watch, would, arriv...              2   \n",
       "\n",
       "            sent_positive  total_articles  day_change increase  open  high  \\\n",
       "2015-01-02              2               7         0.0        1   0.0   0.0   \n",
       "2015-01-05             11              13         0.0        1   0.0   0.0   \n",
       "\n",
       "            low  close    volume  \n",
       "2015-01-02  0.0    0.0  53204600  \n",
       "2015-01-05  0.0    0.0  64285500  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agged.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the cleaned dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe will be used in the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agged.to_pickle('main_data/maindf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('main_data/seperated_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
