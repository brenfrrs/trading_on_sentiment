{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import pytz\n",
    "from nltk.probability import FreqDist\n",
    "from custom_scripts import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39512, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('yearly_articles/apple2020.csv', index_col=0)\n",
    "df2 = pd.read_csv('yearly_articles/apple2019.csv', index_col=0)\n",
    "df3 = pd.read_csv('yearly_articles/apple2018.csv', index_col=0)\n",
    "df4 = pd.read_csv('yearly_articles/apple2017.csv', index_col=0)\n",
    "df5 = pd.read_csv('yearly_articles/apple2016.csv', index_col=0)\n",
    "df6 = pd.read_csv('yearly_articles/apple2015.csv', index_col=0)\n",
    "df = pd.concat([df1,df2, df3, df4, df5, df6])\n",
    "df.dropna(subset=['fulltext'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean newlines and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.64 s, sys: 112 ms, total: 8.75 s\n",
      "Wall time: 8.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['cleaned_text'] = df['fulltext'].apply(clean_text)\n",
    "df['cleaned_authors'] = df['author'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the UTC time to EST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to Datetime\n",
    "df[\"date\"]= pd.to_datetime(df[\"date\"])\n",
    "df = df.set_index('date')\n",
    "df.index = df.index.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 237 ms, sys: 4.33 ms, total: 242 ms\n",
      "Wall time: 243 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#convert DateTime index to eastern time. \n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "df.index = df.index.tz_convert(eastern).tz_localize(None)\n",
    "#put into year/month/day format\n",
    "df.index = df.index.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using [tldextract](https://pypi.org/project/tldextract/) to extract company names from url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 39512 different articles from 448 news outlets \n",
      "\n",
      "CPU times: user 372 ms, sys: 6.63 ms, total: 379 ms\n",
      "Wall time: 382 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['news_outlet'] = df['source'].apply(get_outlet)\n",
    "print('The dataset contains {} different articles from {} news outlets \\n'.format(df.shape[0],df.news_outlet.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting historical Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2010-01-01', '2010-01-31'),\n",
       " ('2010-02-01', '2010-02-28'),\n",
       " ('2010-03-01', '2010-03-31'),\n",
       " ('2010-04-01', '2010-04-30'),\n",
       " ('2010-05-01', '2010-05-31'),\n",
       " ('2010-06-01', '2010-06-30'),\n",
       " ('2010-07-01', '2010-07-31'),\n",
       " ('2010-08-01', '2010-08-31'),\n",
       " ('2010-09-01', '2010-09-30'),\n",
       " ('2010-10-01', '2010-10-31'),\n",
       " ('2010-11-01', '2010-11-30'),\n",
       " ('2010-12-01', '2010-12-31')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_ranges = get_month_day_range(2010)\n",
    "monthly_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 2010-01-01 to 2010-01-31\n",
      "2) 2010-02-01 to 2010-02-28\n",
      "3) 2010-03-01 to 2010-03-31\n",
      "4) 2010-04-01 to 2010-04-30\n",
      "5) 2010-05-01 to 2010-05-31\n",
      "6) 2010-06-01 to 2010-06-30\n",
      "7) 2010-07-01 to 2010-07-31\n",
      "8) 2010-08-01 to 2010-08-31\n",
      "9) 2010-09-01 to 2010-09-30\n",
      "10) 2010-10-01 to 2010-10-31\n",
      "11) 2010-11-01 to 2010-11-30\n",
      "12) 2010-12-01 to 2010-12-31\n",
      "Final shape: (252, 5)\n"
     ]
    }
   ],
   "source": [
    "stock_prices_aapl = get_past_prices(monthly_ranges, 'AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_prices_aapl['day_change'] = np.nan\n",
    "# stock_prices_aapl['increase'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loop below iterates through the historical prices and calculates the change in a stock price from one open to another. Adding a 0 if the stock decreased or there was not change, and adding a 1 if the stock increased. This is an initial tagging step, the threshold for targets can be adjusted later using the 'day_change' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_index = stock_prices_aapl.index.strftime('%Y-%m-%d').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(columns = ['day_change', 'increase', 'date'])\n",
    "for i,stock_price in enumerate(prices_index):\n",
    "    try:\n",
    "        start = stock_prices_aapl.loc[prices_index[i]].open[0]\n",
    "        stop = stock_prices_aapl.loc[prices_index[i+1]].open[0]\n",
    "        direction = start - stop\n",
    "        if direction < 0:\n",
    "            increase = 0\n",
    "        else:\n",
    "            increase = 1\n",
    "        df_res = df_res.append({'day_change': direction, 'increase':increase, 'date':stock_price}, ignore_index=True)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[\"date\"]= pd.to_datetime(df_res[\"date\"])\n",
    "df_res = df_res.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_change</th>\n",
       "      <th>increase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-29</th>\n",
       "      <td>-0.13750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-28</th>\n",
       "      <td>-0.06857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-27</th>\n",
       "      <td>0.03214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            day_change increase\n",
       "date                           \n",
       "2010-01-29    -0.13750        0\n",
       "2010-01-28    -0.06857        0\n",
       "2010-01-27     0.03214        1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_change</th>\n",
       "      <th>increase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-29</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-28</th>\n",
       "      <td>-0.13750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-27</th>\n",
       "      <td>-0.06857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-26</th>\n",
       "      <td>0.03214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-25</th>\n",
       "      <td>0.12286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            day_change increase\n",
       "date                           \n",
       "2010-01-29     0.00000        0\n",
       "2010-01-28    -0.13750        0\n",
       "2010-01-27    -0.06857        0\n",
       "2010-01-26     0.03214        1\n",
       "2010-01-25     0.12286        1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shift all targets by one day because we want to predict one day in the future.\n",
    "targets2020 = df_res.shift(periods=1, fill_value=0)\n",
    "targets2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the historical prices with the daily change we calculated and the targets. \n",
    "targs=pd.merge(targets2020,stock_prices_aapl, how='outer', left_index=True, right_index=True)\n",
    "targs.drop(['day_change_y', 'increase_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_change_x</th>\n",
       "      <th>increase_x</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day_change_y</th>\n",
       "      <th>increase_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>0.04179</td>\n",
       "      <td>1</td>\n",
       "      <td>7.62250</td>\n",
       "      <td>7.66071</td>\n",
       "      <td>7.58500</td>\n",
       "      <td>7.64321</td>\n",
       "      <td>123432400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>-0.00786</td>\n",
       "      <td>0</td>\n",
       "      <td>7.66429</td>\n",
       "      <td>7.69964</td>\n",
       "      <td>7.61607</td>\n",
       "      <td>7.65643</td>\n",
       "      <td>150476200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            day_change_x increase_x     open     high      low    close  \\\n",
       "2010-01-04       0.04179          1  7.62250  7.66071  7.58500  7.64321   \n",
       "2010-01-05      -0.00786          0  7.66429  7.69964  7.61607  7.65643   \n",
       "\n",
       "               volume  day_change_y  increase_y  \n",
       "2010-01-04  123432400           NaN         NaN  \n",
       "2010-01-05  150476200           NaN         NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the targets to the proper folder\n",
    "targs.to_csv('yearly_targets/targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge targets and main data on the date\n",
    "df=pd.merge(df,targs, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Sentiment for each Article with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#tag the sentiment for each article using VADER. This will take a few minutes.\n",
    "df['sentiment'] = df['fulltext'].apply(sentiment_analyzer_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the sentiment distributions.\n",
    "sns.countplot(df.sentiment);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['cleaned_text'].apply(toke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize/Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=list(set(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_stopwords = [\n",
    "    'x', 'u', \"'\", 'e', 'a', 'i', 'n', 'u', 'd', 'c', 'p', 's', 'i',\n",
    "    'o', 'r', 't', 'journalism', 'support', 'u', 'editor', 'fair', 'informed',\n",
    "    'cookie', 'miamiaccording', 'article', 'expired', 'no', 'longer', 'want',\n",
    "    'search', 'google', 'every', 'term', 'newswire', 'subscribe', 'button', 'close',\n",
    "    'accept', 'goal', 'achieve', 'u', 'subscribed', 'many', 'continue', 'offer',\n",
    "    'hard', 'provide', 'dear', 'reader', 'standard', 'always', 'strived', 'miamiinterested',\n",
    "    'adopting', 'pet', 'gazing', 'lovable', 'pup', 'adoption', 'dog', 'animal', 'shelter',\n",
    "    'ziprecruiter', 'miami', 'policy', 'clicking', 'explicit', 'consent',\n",
    "    'please', 'see', 'even', 'better', 'relevant', 'goal', 'le', 'u,', 'philip', 'schiller',\n",
    "    'believe', 'getty', 'josh', 'edelson', 'topical', 'issue', 'relevance',\n",
    "    'seen', 'man', 'forward', 'dunkin', 'late', 'wife', 'bagelsee', 'rental', 'site', 'zumper',\n",
    "    'quarantinefind', 'irvine', 'using', 'yelp', 'find', 'devon', 'horse', 'show',\n",
    "    'urge', 'turn', 'ad', 'blocker', 'telegraph', 'barbecue', 'stop', 'crunched',\n",
    "    'porch', 'ebay', 'amazon', 'curry', 'weeknightsset', 'easy', 'dinner', 'matter', 'partner',\n",
    "    'find', 'detailed', 'description', 'apartment', 'got', 'news', 'mission', 'day', 'impersonal',\n",
    "    'get', 'tip', 'top', 'mirror', 'newsletter', 'sign', 'thank', 'subscribing',\n",
    "    'newsletter', 'invalid', 'full', 'swing', 'keen', 'get', 'hand', 'high', 'street',\n",
    "    'john', 'lewis', 'curry', 'ton', 'currently', 'available', 'actual', 'check', 'back', 'also', 'honor',\n",
    "    'writer', 'try', 'put', 'apartment', 'rent', 'via', 'go', 'rounded', 'dog', 'shelter', 'pup',\n",
    "    'dozen', 'donut', 'south', 'targeted', 'practise', 'floridado', 'love', 'florida', 'doggy',\n",
    "    'cancer', 'hide', 'caption', 'cooky', 'browser', 'sauce', 'pandemicthe',\n",
    "    'something', 'penguina', 'eagle', 'email', 'notification', 'irvinein', 'hoodline',\n",
    "    'recipe', 'perfect', 'meal', 'googlethe', 'v', 'doggy', 'delightful',\n",
    "    'place', 'live', 'retire', 'takeout', 'youtubethe', 'barnes', 'museum',\n",
    "    'cooking', 'nonstick', 'cookware', 'pretzelslearn', 'homemade', 'soft',\n",
    "    'collectionsmany', 'franklin', 'u', 'gotten', 'tour', 'familiesthis',\n",
    "    'best', 'spot', 'noticed', 'adblocking', 'help', 'fund', 'award', 'winning',\n",
    "    'image', 'curry', 'ton', 'miamimiami', 'new', 'jersey', 'photographer',\n",
    "    'authoritative', 'apartment', 'cheapest', 'downtown', 'bedroom', 'adventure',\n",
    "    'aquarium', 'artwork', 'pretzel', 'click', 'play', 'tap', 'play',\n",
    "    'aught', 'newsletter', 'pear', 'david', 'nield', 'gizmodo', 'pic', 'twitter',\n",
    "    'com', 'thimbleweed', 'monument', 'pas', 'afp', 'u', 'prepear' \n",
    "]\n",
    "\n",
    "\n",
    "stop_words.extend(eda_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return [word for word in text if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tokens = df.tokens.apply(unlist)\n",
    "df.tokens = df.tokens.apply(remove_stopwords)\n",
    "df.tokens = df.tokens.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicate tokens.\n",
    "df.tokens.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for additional stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = df.drop_duplicates(subset=['tokens'])\n",
    "text = cloud.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(word for word in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,17))\n",
    "\n",
    "wordcloud = WordCloud(max_words=200,collocations=False, width=1000, height=700, background_color=\"black\").generate(text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "#wordcloud.to_file('all_tweets_wordcloud.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the cleaned dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('main_data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
